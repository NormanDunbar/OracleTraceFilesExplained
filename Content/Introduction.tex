\chapter{Introduction}\label{introduction}

Oracle trace files are not greatly documented. This document is an attempt to do so. It is \emph{not} official in any way and is based on a good few years of reading these files to help diagnose various database problems.

A trace file is really the best way to delve into what Oracle is doing, or to discover why something is taking so long - it shows you exactly what happened during the period that the session was being traced.

Even better, when you extract an Explain Plan from a trace file, it is showing you exactly how Oracle retrieved the data from the tables, and exactly where the time was spend in doing so. Running an \inline{Explain Plan for ...} statement in \emph{SQL*Plus}\program{SQL*Plus}, \emph{Toad}\program{Toad} etc tells you what Oracle \emph{might} do. The two are not always the same.

The trace files used (and abused) in this eBook were all self contained, and extracted from a dedicated session on the database. If you are using shared sessions, then you have the unfortunate problem of having bits of your session trace spread over any number of different trace files. Not fun.

From Oracle 10g onwards, a utility has been supplied, named \emph{trcsess}\program{Trcsess}. This allows you to collect together all the separate files and merge them into one, ready for analysis. Even better, it apparently can also merge Oracle 9i shared server session trace files. Bonus!

\section*{Trace File Extracts}

In the remainder of this eBook, extracts from trace files will be shown as follows:

\begin{lstlisting}[numbers=none]
WAIT #3220341128: nam='db file sequential read' ela= 1023 file#=3 block#=12 blocks=1 obj#=-1 tim=3520817183625
\end{lstlisting}

You will notice that long lines from the trace file are wrapped in the example above. However, all such wrapped lines are indicated by a \textbf{$\Longrightarrow$} at the start of the continuation line(s). Sometimes though, the break in the lines can be at an awkward position. Sadly, I can't help this, it's all automagically done and I have no input as to how, exactly, \LaTeX{} decides.

\section*{Code Listings}

SQL scripts (or any other program listings) will be listed as per the example below. The only difference being line numbers, in case I have to reference a particular point, and syntax highlighting.

\begin{lstlisting}[language=SQL]
select name, parameter1, parameter2, parameter3
from   v$event_name
where  name = 'db file sequential read';
\end{lstlisting}

\section*{Irregular Updates}

This eBook is a work in progress, I am always learning, or trying to. As I update it, the latest version will always appear on GitHub as detailed on the Copyright page above. Also on that page, you will be able to see the date and time that the version of the eBook you are reading, was generated. That's done automagically too, so I don't need to remember to update it - thankfully!

\section*{Comments}

Seen anything blatantly wrong? Something  you think needs a better explanation? Too many blatant plugs? You can either create an issue on GitHub, or, \href{mailto://norman@dunbar-it.co.uk}{email me} with details and I'll do my best to get it fixed.

\chapter{Trace File Gotchas!}\label{tracefilegotchas}

Trace files can be full of pitfalls and traps for the unwary. Best take care!

\section{Things to Beware Of}

There are a few things to watch out for in trace files, some of these are mentioned frequently in the text below, but they are also gathered here together, in one place, for your convenience.\footnote{Ok, for \emph{my} convenience!}
	
\subsection{When Are Lines Written to the Trace File?}

It cannot be said often enough, \emph{a line in the trace file is written when that particular action has completed} and not before. So, if you see a line defining a \inline{PARSE} statement in the trace file, the \inline{PARSE} has completed at that point. The \inline{tim} value gives you the (relative) time that the action completed. 

\subsection{Tim Values}

On 11g \inline{tim} values are in microseconds, or, millionths of a second, and are an offset from some epoch, which itself depends on the Operating System in use.

You can get a rough idea of how long a statement took by subtracting the previous \inline{tim} from the current \inline{tim} - the answer is in microseconds, so count back 6 places from the right end of the \inline{tim} value, and shove in a decimal point.

Alternatively, use my \program{TraceAdjust}\inline{TraceAdjust} utility to convert \inline{tim} values into date and times accurate to the microsecond. (Plug! See Appendix~\ref{traceadjust} on page~\pageref{traceadjust} for details.)

\subsection{Timestamps}

Not all actions in the trace file may be \emph{accurately} timed. This can lead to the various \inline{tim} values getting slightly out of step. To attempt to alleviate this, Oracle will write timestamp lines to the trace file. These are flagged by three asterisks (\inline{***}) followed by the date and time, accurate to microsecond level, possibly in the format \inline{yyyy-mm-dd hh24:mi:ss.u} but this \emph{might} depend on locality etc. The \inline{tim} value immediately following these timestamp lines are adjusted to match the timestamp that preceded it.

You can see an example of a timestamp line in the header for the trace file. An example is in Section~\ref{the-header} on Page~\pageref{the-header}.


\subsection{Cursor Depth}\index{Cursor Depth}

Cursors are parsed, executed etc at a given depth. This can be seen in the \inline{dep=$n$} details in the appropriate lines in the trace file.

If the listed depth is zero, then this is the top level SQL in the trace file, and usually corresponds to your own statements. Statements running in a PL/SQL procedure, function etc, however, \emph{may} be listed at a different depth with the call to the procedure (or whatever) being run at depth zero.

As mentioned above, lines are written to the trace file when an action completes, so you will see (at least in most trace files) the \inline{PARSE}, \inline{EXEC} and \inline{FETCH} and possibly \inline{STAT} and/or \inline{CLOSE} for the recursive SQL statements \emph{after} the \inline{PARSE} but \emph{before} the \inline{EXEC} for your statement. Simply because of the need to execute all those recursive statements in order to facilitate the \inline{EXEC} of yours.

If you see a statement being actioned at dep=$n$, where $n <> 0$, then it is being actioned recursively for another statement at dep=$n-1$ which \emph{follows later} in the trace file.

\subsection{Cursor IDs Get Reused}\index{Cursor ID Reuse}

When you see something like \inline{PARSE \#1234567890} then the digits after the \# are the cursor ID. In the old days, prior to Oracle 9i, cursor IDs were monotonically increasing and were never reused in the same trace file. Once cursor \#1 had been closed, you wouldn't see it again.

This is no longer true and a cursor ID \emph{can} be reused once closed. There are two (known to me) variations:

\subsubsection{Same SQL Statement Reused by Same CursorID}

Some applications write SQL that is parsed far too frequently and may even be parsed each and every time it is executed by the application code. If this is the case, the trace files \emph{may} show the following steps

\begin{itemize}
	\item \inline{CLOSE} of the current cursor.
	\item \emph{Possibly} a \inline{PARSE} for the new statement. This will not be present if the previous \inline{CLOSE} resulted in the cursor being cached.
	\item And so on.
\end{itemize}

If the same statement is reparsed and nothing else has been parsed since the \inline{CLOSE}, then it is possible that the expected \inline{PARSING IN CURSOR} line, showing the SQL text, may be missing from the trace file.

If the same statement has been parsed three or more times already, Oracle may cache the cursor rather than hard \inline{CLOSE}ing it as this is a performance improvement if the SQL has to be \inline{PARSE}d and \inline{EXEC}uted again. In this case, there will be no \inline{PARSE} line in the trace file for the statement - simply because it was not actually \inline{PARSE}d, merely retrieved from the cache already \inline{PARSE}d.

\subsubsection{Different SQL using Same Cursor ID}

If a statement's cursor is closed and another \emph{different} statement is parsed, it \emph{can} obtain the same Cursor ID as the recently closed cursor. In this case, you will see the following:

\begin{itemize}
	\item \inline{CLOSE} of the current cursor.
	\item \inline{PARSING IN CURSOR} and the SQL text of the new statement.
	\item \inline{PARSE} for the new statement.
	\item And so on.
\end{itemize}

The moral to this tale is simple, you cannot be sure that all the \inline{EXEC}s for a given Cursor ID actually mean that the exact same SQL statement has been executed - you could be seeing lots of different SQL statements simply reusing the same Cursor ID.

\subsection{What About Child Cursors?}\index{Child Cursors}

Following on from the above, the same SQL statement \emph{can} (and does) have the ability to be executed under any number of \emph{different} Cursor IDs! How is this possible?

If your statement uses bind variables, then given a recent enough version of Oracle, something called \emph{Bind Variable Peeking} or \emph{Adaptive Cursor Sharing} may be in use to ensure that a statement has the most efficient plan of execution regardless of the bind variable values in use, or changes to them between executions. In the good old days, whatever bind value got in first determined the execution plan for every other \inline{EXEC} of that statement, even if it made the execution plan completely hopeless for most values that followed.

\emph{Adaptive Cursor Sharing}, for certain bind values, will cause a number of separate child cursors, and thus, different Cursor IDs in the trace file, for the same statement (ie, the same \emph{sql\_id}). A recent trace file I examined had 15 different Cursor IDs for the same statement. 

I knew they were all the same as the \inline{PARSING IN CURSOR} line has the \inline{sqlid} at the end, and although the Cursor IDs were different, the SQL Text and such like were all the same and so was the \inline{sqlid} so it \emph{had} to be the same SQL statement, just with numerous child cursors. Beware of this when looking in trace files!

If you know the \inline{sqlid} then you can count and find any and all child cursors, and their IDs in the trace file with a swift grep command.

The following command will count the number of child cursors in the trace file for the SQL statement with \inline{sqlid 0um91dczrf666}:

\begin{lstlisting}[numbers=none,caption={Counting Child Cursors in a Trace File}]
grep -i "0um91dczrf666" TraceFile.trc | wc -l
\end{lstlisting}

The following command will extract, in the order of appearance in the trace file, all the child cursors for the same statement as above:

\begin{lstlisting}[numbers=none,caption={Extracting Child Cursors from a Trace File}]
grep -i "0um91dczrf666" TraceFile.trc | cut -c 20-39
\end{lstlisting}

This was an HP-UX trace file, so the digits after the \# in the Cursor ID were from position 20 to 39 in the output from \inline{grep}. Other Operating Systems may differ, so test on yours first, just in case.

